#summary Description of Miner module
#labels Phase-Requirements,Phase-Design

= Miner =

This component is responsible for mining knowledge from collected in allmon database data. 

Provides: 
  * Access layer to allmon database - used for viewer and other visualization tools 
  * Aggregating procedures (algorithms)
    * Saving space, fastening queries
    * Loosing details
    * Possible pruning old metrics in allmetric storage after aggregating (saving space)
  * Statistical analysis procedures
    * Correlation across set up dimensions
  * Storing events history log
  * Data mining algorithms
    * Clusterization
    * ...

== Aggregates ==

  * Scalar metrics
    * In-time 
      * For boolean values - point to point change aggregation (very effective if changes are not often)
      * *1minute*, 15m, 30m, *1h*, 2h, 3h, 6h, 12h, *1d*, 2d, 1w, 1month, ...
    * ...
  * Vector metrics
    * In-time aggregation (day, hour, etc.)
      * Aggregated servlet calls in days/hours
    * In resource/source hierarchy level aggregation 
      * Aggregated servlet calls in hours for classes (resource) - users (source) and session is lost
    * Aggregated calls by count of concurrent calls (in second grain)
    * ...
  
  * Aggregate functions
    * Min/Max - very good to describe spread
    * Avg - base aggregation for most scalar metrics
    * Sum - basis for execution times metrics
    * Median - can be useful because median is a central point which minimizes the average of the absolute deviations
    * First/Last - together with Min/Max can be used to give candlestick analysis over time (http://en.wikipedia.org/wiki/Candlestick_chart)
    * Stddev - especially good for metrics describing activity with gausian (normal) distribution
    * Poison k, m
    * Distribution - storing histogram or bitmap function of metrics values - very effective way of aggregating for coarse grained aggregates

  * Aggregate procedures can be set for specific time period, i.e.:
    * servlet calls contain resource: class, source: user - for 500k calls per day in a system with 100 servlet classes used by 1000 users with constant distribution on 24x7 basis, gives 500k rows per day -> 3.5M rows per week -> 15M rows per month
      * _hour_ aggregation of servlet calls per user (class name is not taken into account) _for last three months_ only - 24 hours x 500 users = 12k rows per day - 360k rows per month and 1M rows overall 
      * _day_ aggregates of servlet calls per user _for last year_ - 1 day x 500 users = 500 rows per day - 15k rows per month - 180k per year

  * All aggregation procedures contain estimation algorithm which helps decide about parameters to balance usability of aggregated data and space needed for their storage
    * taking above example, all figures can be estimated using the same distribution as already stored in not aggregated (detailed) data  

== Statistical analysis ==

  * Correlation
    * Detecting related events in metrics of many layers of monitored systems infrastructure
    * Autocorrelation - http://web.science.mq.edu.au/~cassidy/comp449/html/ch05s02.html
    * Finding pseudo-related events (before/after) health check value change
  * Filtration
    * Detecting and removing outliners or noise - i.e. before aggregation to minimize round-off errors
  * Trend detection
    * Extrapolation
    * Forecasting
    * "aberrant behavior detection"
  * Simple statistics
    * Up time (in log) 
  * Analysis in frequency domain (after Fourier transform)
    * http://en.wikipedia.org/wiki/Frequency_domain
    * http://web.science.mq.edu.au/~cassidy/comp449/html/ch06.html
  * ...

== Data mining ==

  * Clusterization - hierarchical and mean-based - identifying similarities in users/methods behaviour
  * Graphs of interconnections between resources and sources (who/what is using what)
  * ...